{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de Hyper-parámetros\n",
    "\n",
    "Prácticamente todos los algoritmos de aprendizaje automático tienen una serie de parámetros que regulan la forma en la cual son entrenados. Por convención, los mismos son llamados hyper-parámetros, para diferenciarlos de los que el modelo aprende como función de los datos de entrenamiento.  \n",
    "\n",
    "En líneas generales, el modelado de un problema predictivo puede separase en tres etapas:\n",
    "\n",
    "1. Determinación del Modelo y del algoritmo de entrenamiento\n",
    "2. Determinación de los hyper-parámetros del algoritmo / modelo\n",
    "3. Determinación de los parámetros del modelo\n",
    "\n",
    "Si bien \"algoritmo de aprendizaje\" y \"modelo\" suelen usarse con el mismo significado, por su estrecha relación, en términos rigurosos, son dos conceptos separados. El modelo es una abstracción matemática de la realidad mientras que el algoritmo es la receta para encontrar los parámetros del modelo. Por ejemplo, un modelo es la regresión logística, sobre el cual existen una cantidad de algoritmos de entrenamiento que, en esencia, son distintos métodos numéricos de optimización de funciones. \n",
    "\n",
    "Una vez seleccionados modelo y algoritmo, se deben determinar ciertos hyper-parámetros. Algunos de ellos son propios del modelo y otros de algoritmo de aprendizaje. Por ejemplo, la profundidad máxima de un árbol de decisión es un hyper-parámetro del modelo, mientras que la función de pérdida (gini o entropía) corresponde al algoritmo. \n",
    "\n",
    "Finalmente, los parámetros del modelo son justamente los que determina el algoritmo de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos de optimización\n",
    "\n",
    "Existen esencialmente tres formas de encarar la optimización de hyper-parámetros\n",
    "\n",
    "1. búsqueda exhaustiva (gridsearch)\n",
    "2. búsqueda aleatoria (random search)\n",
    "3. otros métodos más \"inteligentes\" (por ejemplo, optimización bayesiana)\n",
    "\n",
    "La búsqueda exhaustiva consiste en explorar los más posible el espacio de hyper-parámetros para encontrar el óptimo, se lo puede ver como un método de fuerza bruta. Sólo es viable si cada evaluación funcional es \"barata\", computacionalmente hablando. \n",
    "\n",
    "La búsqueda aleatoria, consiste en tomar muestras al azar del espacio de hp, teniendo la expectativa de que se puede llegar a un valor lo suficientemente cercano al óptimo sin tener que explorar el espacio completo. Este método pretende llegar a un resultado similar al anterior, pero con muchas menos evaluaciones funcionales. Una de las lecturas del teorema de \"no free lunch\" implica que, si tomamos todos los posibles problemas de optimización, en promedio, ningún método encontrará el óptimo más rápido que la búsqueda al azar. O, dicho de otra manera, no existe ningún algoritmo de búsqueda más eficiente que la búsqueda al azar para todos los posibles problemas de optimización. \n",
    "\n",
    "Los demás métodos \"inteligentes\" pretenden encontrar el óptimo más rápidamente pero, de acuerdo con el teorema de no free lunch, son realmente más rápidos en un subconjunto de los problemas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup para el notebook\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "plt.rcParams['figure.figsize'] = (16, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/Argentan/DMA_LAB2/master/data/titanic_proc.csv\", index_col=\"PassengerId\")\n",
    "\n",
    "X = data.drop(\"Survived\", axis=1)\n",
    "y = data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busqueda exhaustiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [[tr, te] for tr, te in StratifiedKFold(3).split(X, y)]\n",
    "def sample_score(params):\n",
    "    C = 10 ** params[0]\n",
    "    gamma = 10 ** params[1]\n",
    "    print(\"*\"*10)\n",
    "    print(\"haciendo\", C, gamma)\n",
    "    res = cross_val_score(SVC(C=C, gamma=gamma),\n",
    "                           X=X, y=y, scoring='roc_auc', cv=folds).mean()\n",
    "    print(\"el resultado fue\", res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.linspace(5, -5, 5)\n",
    "gammas = np.linspace(7, -7, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# tomamos el producto cartesiano entre los dos arrays de parametros\n",
    "param_grid = np.array([[C, gamma] for gamma in gammas for C in lambdas])\n",
    "\n",
    "real_loss = [sample_score(params) for params in param_grid]\n",
    "\n",
    "# el máximo está en:\n",
    "optima = param_grid[np.array(real_loss).argmax(), :]\n",
    "optima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C, G = np.meshgrid(lambdas, gammas)\n",
    "plt.figure()\n",
    "cp = plt.contourf(C, G, np.array(real_loss).reshape(C.shape), cmap=plt.cm.Pastel1)\n",
    "plt.colorbar(cp)\n",
    "plt.title('Contorno coloreado del espacio de búsqueda')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Gamma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C, G = np.meshgrid(lambdas, gammas)\n",
    "plt.figure()\n",
    "cp = plt.contourf(C, G, np.array(real_loss).reshape(C.shape), cmap=plt.cm.Pastel1)\n",
    "plt.colorbar(cp)\n",
    "plt.title('Contorno coloreado del espacio de búsqueda')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Gamma')\n",
    "plt.vlines(lambdas, gammas.min(), gammas.max(), color=\"white\")\n",
    "plt.hlines(gammas, lambdas.min(), lambdas.max(), color=\"white\")\n",
    "plt.scatter(optima[0], optima[1], marker='*', c='gold', s=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#búsqueda aleatoria\n",
    "\n",
    "C, G = np.meshgrid(lambdas, gammas)\n",
    "plt.figure()\n",
    "cp = plt.contourf(C, G, np.array(real_loss).reshape(C.shape), cmap=plt.cm.Pastel1)\n",
    "plt.colorbar(cp)\n",
    "plt.title('Contorno coloreado del espacio de búsqueda')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Gamma')\n",
    "for p in range(100):\n",
    "    px = np.random.uniform(lambdas.min(), lambdas.max())\n",
    "    py = np.random.uniform(gammas.min(), gammas.max())\n",
    "    plt.plot(px, py, marker='o', color='black')\n",
    "plt.scatter(optima[0], optima[1], marker='*', c='gold', s=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
